---本文档方法，代码总结来自于：

[蒙特卡洛树搜索最通俗入门指南 - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/53948964)

[28 天自制你的 AlphaGo (6) : 蒙特卡洛树搜索（MCTS）基础 - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/25345778)

总结：蒙特卡洛在处理庞大的棋盘情况的时候，更有优势。

## 蒙特卡洛 MCTS

### 思想

双方在某个局面下「随机」走子，注意是「随机」走，走到终局或者残局为止，随机很多次（比如一万盘），计算胜率，胜率越高的局面就越好。

### 构成

![img](https://pic1.zhimg.com/80/v2-b958662a0be8daf52bea1cd735a7575c_720w.webp)

蒙特卡洛树搜索，它肯定是棵搜索树

#### 构成要素

1. **选择**（Selection）

   ## **选择（Selection）**

   我们将节点分成三类：

   - 未访问：还没有评估过当前局面
   - 未完全展开：被评估过至少一次，但是子节点（下一步的局面）没有被全部访问过，**可以进一步扩展**
   - 完全展开：子节点被全部访问过
     我们找到**目前认为**「最有可能会走到的」一个未被评估的局面（双方都很聪明的情况下），并且**选择**它。
   - UCT算法，![image-20230708222505894](C:\Users\GongT\AppData\Roaming\Typora\typora-user-images\image-20230708222505894.png)
     - Q(v) 是该节点赢的次数，N(v) 是该节点模拟的次数，C 是一个常数。
       因此我们每次选择的过程如下——从根节点出发，遵循最大最小原则，每次选择己方 UCT 值最优的一个节点，向下搜索，直到找到一个
       「未完全展开的节点」，根据我们上面的定义，未完全展开的节点一定有未访问的子节点，随便选一个进行扩展。

2. **扩展** (expansion)

   - 将刚刚选择的节点加上一个统计信息为「0/0」的节点，然后进入下一步模拟（Simluation）

3. **模拟**（Simulation）

   - 先讲模拟，模拟借鉴了我们上面说的蒙特卡洛方法，**快速走子**，*只走一盘*，分出个胜负。
     我们每个节点（每个节点代表每个不同的局面）都有两个值，代表这个节点以及它的子节点模拟的次数和赢的次数，比如模拟了 10 次，赢了 4 盘，记为 4/10。

4. **回溯**（Backpropagation）

   - 递归里的回溯，用于父节点统计信息
   - ![img](https://pic1.zhimg.com/80/v2-b958662a0be8daf52bea1cd735a7575c_720w.webp)

#### Q:蒙特卡洛是什么？

1. 评判棋盘局面的一种方法

